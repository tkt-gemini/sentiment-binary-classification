"""
Prediction/Inference Module
Module Ä‘á»ƒ dá»± Ä‘oÃ¡n cáº£m xÃºc cho vÄƒn báº£n má»›i
"""

import joblib
import numpy as np
from typing import List, Tuple, Dict
from utils import preprocess_text


class SentimentPredictor:
    """
    Class Ä‘á»ƒ thá»±c hiá»‡n dá»± Ä‘oÃ¡n cáº£m xÃºc
    """
    
    def __init__(self, model_dir: str = 'models'):
        """
        Khá»Ÿi táº¡o predictor
        
        Parameters:
        -----------
        model_dir : str
            ÄÆ°á»ng dáº«n tá»›i thÆ° má»¥c chá»©a models
        """
        self.model_dir = model_dir
        self.pipeline = None
        self.label_encoder = None
        self.stopwords = None
        self.metadata = None
        
        self._load_models()
    
    def _load_models(self):
        """Load táº¥t cáº£ models vÃ  components cáº§n thiáº¿t"""
        try:
            self.pipeline = joblib.load(f'{self.model_dir}/sentiment_pipeline.pkl')
            self.label_encoder = joblib.load(f'{self.model_dir}/label_encoder.pkl')
            self.metadata = joblib.load(f'{self.model_dir}/model_metadata.pkl')
            
            # Load stopwords náº¿u cÃ³
            try:
                self.stopwords = joblib.load(f'{self.model_dir}/stopwords.pkl')
            except:
                self.stopwords = set()
            
            print(f"âœ… ÄÃ£ táº£i model: {self.metadata.get('model_name', 'N/A')}")
            print(f"   Threshold: {self.metadata.get('optimal_threshold', 0.5):.4f}")
            print(f"   F1-Score (Test): {self.metadata.get('f1_score', 0):.4f}")
            
        except Exception as e:
            raise RuntimeError(f"KhÃ´ng thá»ƒ táº£i model: {e}")
    
    def predict_single(self, text: str) -> Dict:
        """
        Dá»± Ä‘oÃ¡n cáº£m xÃºc cho má»™t cÃ¢u
        
        Parameters:
        -----------
        text : str
            VÄƒn báº£n cáº§n phÃ¢n tÃ­ch
        
        Returns:
        --------
        Dict : Dictionary chá»©a káº¿t quáº£ dá»± Ä‘oÃ¡n
            - text: vÄƒn báº£n gá»‘c
            - processed: vÄƒn báº£n sau xá»­ lÃ½
            - sentiment: nhÃ£n cáº£m xÃºc (positive/negative)
            - sentiment_encoded: nhÃ£n encode (0/1)
            - probability: xÃ¡c suáº¥t cá»§a lá»›p dá»± Ä‘oÃ¡n
            - prob_negative: xÃ¡c suáº¥t lá»›p negative
            - prob_positive: xÃ¡c suáº¥t lá»›p positive
        """
        # 1. Tiá»n xá»­ lÃ½
        processed_text = preprocess_text(text, self.stopwords)
        
        if not processed_text:
            return {
                'text': text,
                'processed': '',
                'sentiment': 'unknown',
                'sentiment_encoded': -1,
                'probability': 0.0,
                'prob_negative': 0.0,
                'prob_positive': 0.0
            }
        
        # 2. Láº¥y threshold
        threshold = self.metadata.get('optimal_threshold', 0.5)
        
        # 3. Dá»± Ä‘oÃ¡n xÃ¡c suáº¥t
        if hasattr(self.pipeline, 'decision_function'):
            # Cho SVM
            decision = self.pipeline.decision_function([processed_text])[0]
            prob_positive = 1 / (1 + np.exp(-decision))
            prob_negative = 1 - prob_positive
        else:
            # Cho LR vÃ  NB
            probs = self.pipeline.predict_proba([processed_text])[0]
            prob_negative = probs[0]
            prob_positive = probs[1]
        
        # 4. Ãp dá»¥ng threshold
        if prob_positive >= threshold:
            sentiment_idx = 1
        else:
            sentiment_idx = 0
        
        sentiment_label = self.label_encoder.inverse_transform([sentiment_idx])[0]
        probability = prob_positive if sentiment_idx == 1 else prob_negative
        
        return {
            'text': text,
            'processed': processed_text,
            'sentiment': sentiment_label,
            'sentiment_encoded': sentiment_idx,
            'probability': probability,
            'prob_negative': prob_negative,
            'prob_positive': prob_positive
        }
    
    def predict_batch(self, texts: List[str]) -> List[Dict]:
        """
        Dá»± Ä‘oÃ¡n cáº£m xÃºc cho nhiá»u cÃ¢u
        
        Parameters:
        -----------
        texts : List[str]
            Danh sÃ¡ch cÃ¡c vÄƒn báº£n cáº§n phÃ¢n tÃ­ch
        
        Returns:
        --------
        List[Dict] : Danh sÃ¡ch káº¿t quáº£ dá»± Ä‘oÃ¡n
        """
        results = []
        for text in texts:
            result = self.predict_single(text)
            results.append(result)
        return results
    
    def get_model_info(self) -> Dict:
        """
        Láº¥y thÃ´ng tin vá» model
        
        Returns:
        --------
        Dict : ThÃ´ng tin model
        """
        return self.metadata


def predict_from_cli():
    """
    HÃ m Ä‘á»ƒ cháº¡y prediction tá»« command line
    """
    import argparse
    
    parser = argparse.ArgumentParser(description='Dá»± Ä‘oÃ¡n cáº£m xÃºc cho vÄƒn báº£n tiáº¿ng Viá»‡t')
    parser.add_argument('--text', type=str, help='VÄƒn báº£n cáº§n phÃ¢n tÃ­ch')
    parser.add_argument('--file', type=str, help='File chá»©a danh sÃ¡ch vÄƒn báº£n (má»—i dÃ²ng má»™t cÃ¢u)')
    parser.add_argument('--model_dir', type=str, default='models', help='ThÆ° má»¥c chá»©a models')
    
    args = parser.parse_args()
    
    # Khá»Ÿi táº¡o predictor
    predictor = SentimentPredictor(model_dir=args.model_dir)
    
    print("\n" + "="*70)
    print("ğŸ­ PHÃ‚N TÃCH Cáº¢M XÃšC TIáº¾NG VIá»†T")
    print("="*70)
    
    # Xá»­ lÃ½ input
    if args.text:
        # PhÃ¢n tÃ­ch má»™t cÃ¢u
        texts = [args.text]
    elif args.file:
        # PhÃ¢n tÃ­ch tá»« file
        try:
            with open(args.file, 'r', encoding='utf-8') as f:
                texts = [line.strip() for line in f if line.strip()]
        except FileNotFoundError:
            print(f"âŒ KhÃ´ng tÃ¬m tháº¥y file: {args.file}")
            return
    else:
        # Interactive mode
        print("\nğŸ’¬ Nháº­p vÄƒn báº£n cáº§n phÃ¢n tÃ­ch (Ä‘á»ƒ trá»‘ng Ä‘á»ƒ thoÃ¡t):\n")
        texts = []
        while True:
            text = input("ğŸ“ VÄƒn báº£n: ").strip()
            if not text:
                break
            texts.append(text)
    
    # Dá»± Ä‘oÃ¡n
    if texts:
        results = predictor.predict_batch(texts)
        
        print("\n" + "="*70)
        print("ğŸ“Š Káº¾T QUáº¢ PHÃ‚N TÃCH")
        print("="*70)
        
        for i, result in enumerate(results, 1):
            sentiment = result['sentiment']
            emoji = "ğŸ˜Š" if sentiment == "positive" else "ğŸ˜”"
            prob = result['probability']
            
            print(f"\n[{i}] {result['text']}")
            print(f"    âœ {emoji} {sentiment.upper()} ({prob:.1%})")
            print(f"       TÃ­ch cá»±c: {result['prob_positive']:.1%} | TiÃªu cá»±c: {result['prob_negative']:.1%}")
        
        print("\n" + "="*70)


if __name__ == "__main__":
    predict_from_cli()

